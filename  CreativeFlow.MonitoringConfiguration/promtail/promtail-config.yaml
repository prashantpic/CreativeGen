# Configuration file for Promtail, the log shipping agent for Loki.
# This configures Promtail to discover and scrape logs from Kubernetes pods
# and forward them to the Loki server.
# Requirement(s) Addressed: DEP-005, QA-003, INT-007

server:
  http_listen_port: 9080
  grpc_listen_port: 0

# Path to a file where Promtail can store its read position in log files.
# This ensures that logs are not lost or duplicated on restart.
positions:
  filename: /tmp/positions.yaml

# Configures the Loki server endpoint(s) to send logs to.
clients:
  - url: http://loki:3100/loki/api/v1/push

# Defines the log sources to be scraped.
scrape_configs:
  # This job discovers all pods in the Kubernetes cluster and scrapes their logs.
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: __host__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - action: replace
        source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - action: replace
        source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
      - replacement: /var/log/pods/*$1/*.log
        source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
        separator: /
        target_label: __path__

    # Pipeline stages are used to parse and enrich log lines before sending them to Loki.
    pipeline_stages:
      # For CRI-compatible runtimes (containerd, CRI-O), this stage parses the log header.
      - cri: {}
      # If logs are structured as JSON, this stage parses the line and extracts key-value pairs.
      - json:
          expressions:
            level: level
            msg: message
            ts: time
            traceID: traceID
            spanID: spanID
      # Promote extracted JSON fields to Loki labels for efficient querying.
      - labels:
          level:
          traceID:
          spanID:
      # Use the timestamp from the log line if available, for more accurate timing.
      - timestamp:
          source: ts
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
      # Set the main log message content.
      - output:
          source: msg

  # This job specifically targets AI model pods for potentially different labeling or parsing.
  - job_name: ai-custom-models
    kubernetes_sd_configs:
      - role: pod
        selectors:
          - role: LabeledPods
            label: "app.kubernetes.io/component=ai-model"
    relabel_configs:
      # --- Standard Kubernetes relabeling ---
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: __host__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - action: replace
        source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - action: replace
        source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
      - replacement: /var/log/pods/*$1/*.log
        source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
        separator: /
        target_label: __path__

      # --- AI Model specific relabeling ---
      - source_labels: [__meta_kubernetes_pod_label_ai_model_name]
        target_label: model_name
      - source_labels: [__meta_kubernetes_pod_label_ai_model_version]
        target_label: model_version

    # This pipeline is identical to the general one but could be customized
    # with different regex or JSON parsing if AI models have a unique log format.
    pipeline_stages:
      - cri: {}
      - json:
          expressions:
            level: level
            msg: message
            ts: time
            traceID: traceID
            spanID: spanID
            model_event: event_type
            inference_id: id
      - labels:
          level:
          traceID:
          spanID:
          model_event:
          inference_id:
      - timestamp:
          source: ts
          format: RFC3339Nano
      - output:
          source: msg